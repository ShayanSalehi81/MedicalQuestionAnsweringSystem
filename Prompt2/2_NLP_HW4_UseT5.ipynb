{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe8IOnbwJXI8"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install rouge_score\n",
        "!pip install bert-score transformers\n",
        "!pip install jovian --upgrade --quiet\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8vKlQH-I_0H"
      },
      "source": [
        "##Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZZ8h1hWJOKL"
      },
      "source": [
        "Bleu{1,2,3,4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft7eoNooJMvh",
        "outputId": "32f74ea5-20d0-4cb0-caa5-49997ee7400b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'BLEU-1': 0.42857142857142855, 'BLEU-2': 0.26726124191242434, 'BLEU-3': 0.11511121735118796, 'BLEU-4': 0.07730551756939454}\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def calculate_bleu(candidate, references):\n",
        "    candidate_tokens = nltk.word_tokenize(candidate)\n",
        "    reference_tokens = [nltk.word_tokenize(ref) for ref in references]\n",
        "\n",
        "    smoothing = SmoothingFunction().method1\n",
        "    bleu_1 = sentence_bleu(reference_tokens, candidate_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothing)\n",
        "    bleu_2 = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing)\n",
        "    bleu_3 = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothing)\n",
        "    bleu_4 = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing)\n",
        "\n",
        "    return {\n",
        "        'BLEU-1': bleu_1,\n",
        "        'BLEU-2': bleu_2,\n",
        "        'BLEU-3': bleu_3,\n",
        "        'BLEU-4': bleu_4\n",
        "    }\n",
        "\n",
        "candidate = \"The study investigates the effect of ...\"\n",
        "references = [\"This research explores the impact of ...\"]\n",
        "bleu_scores = calculate_bleu(candidate, references)\n",
        "print(bleu_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z96W2QoAJgbZ",
        "outputId": "25868a48-c87f-41a6-97dd-60cd56f1a573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ROUGE-1': 0.3333333333333333, 'ROUGE-2': 0.0, 'ROUGE-L': 0.3333333333333333}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_rouge(candidate, reference):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    scores = scorer.score(reference, candidate)\n",
        "\n",
        "    return {\n",
        "        'ROUGE-1': scores['rouge1'].fmeasure,\n",
        "        'ROUGE-2': scores['rouge2'].fmeasure,\n",
        "        'ROUGE-L': scores['rougeL'].fmeasure\n",
        "    }\n",
        "\n",
        "candidate = \"The study investigates the effect of ...\"\n",
        "reference = \"This research explores the impact of ...\"\n",
        "rouge_scores = calculate_rouge(candidate, reference)\n",
        "print(rouge_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y0P15LaVClKp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26fMEjz8CnPa"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bJTjfRRfCvDr"
      },
      "outputs": [],
      "source": [
        "def compute_bertscore(candidates, references, model, tokenizer, lang='fa'):\n",
        "    candidate_tokens = [tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True) for text in candidates]\n",
        "    reference_tokens = [tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True) for text in references]\n",
        "\n",
        "    candidate_embeddings = [model(tokens)[0].squeeze(0) for tokens in candidate_tokens]\n",
        "    reference_embeddings = [model(tokens)[0].squeeze(0) for tokens in reference_tokens]\n",
        "\n",
        "    P, R, F1 = bert_score.score(candidates, references, model_type=\"HooshvareLab/bert-fa-base-uncased\", lang='fa', rescale_with_baseline=False)\n",
        "\n",
        "    return P, R, F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Svr_99N9Dn9a"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(texts, tokenizer, model):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state\n",
        "    attention_mask = inputs.attention_mask\n",
        "    return embeddings, attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "as0sjueIEECk"
      },
      "outputs": [],
      "source": [
        "def compute_bert_score(candidate_embeddings, reference_embeddings, candidate_mask, reference_mask):\n",
        "    candidate_embeddings = candidate_embeddings.cpu().numpy()\n",
        "    reference_embeddings = reference_embeddings.cpu().numpy()\n",
        "\n",
        "    candidate_mask = candidate_mask.cpu().numpy()\n",
        "    reference_mask = reference_mask.cpu().numpy()\n",
        "\n",
        "    similarities = cosine_similarity(candidate_embeddings.reshape(-1, candidate_embeddings.shape[-1]),\n",
        "                                     reference_embeddings.reshape(-1, reference_embeddings.shape[-1]))\n",
        "\n",
        "    similarities = similarities.reshape(candidate_embeddings.shape[1], reference_embeddings.shape[1])\n",
        "\n",
        "    candidate_mask = candidate_mask[0]\n",
        "    reference_mask = reference_mask[0]\n",
        "\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for i in range(candidate_embeddings.shape[1]):\n",
        "        if candidate_mask[i] == 0:\n",
        "            continue\n",
        "        candidate_sim = similarities[i, :reference_mask.sum()]\n",
        "        precision = candidate_sim.max()\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "    for j in range(reference_embeddings.shape[1]):\n",
        "        if reference_mask[j] == 0:\n",
        "            continue\n",
        "        reference_sim = similarities[:candidate_mask.sum(), j]\n",
        "        recall = reference_sim.max()\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_scores)\n",
        "    recall = np.mean(recall_scores)\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WUwVX6l4C64I"
      },
      "outputs": [],
      "source": [
        "references = [\"this is really bad.\"]\n",
        "candidates = [\"yes this university is really big and good.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nm7DD7jXDrV5"
      },
      "outputs": [],
      "source": [
        "candidate_embeddings, candidate_mask = get_embeddings(candidates, tokenizer, model)\n",
        "reference_embeddings, reference_mask = get_embeddings(references, tokenizer, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HAbPdAb1C1vG"
      },
      "outputs": [],
      "source": [
        "# P, R, F1 = bert_score.score(\n",
        "#     cands=candidates,\n",
        "#     refs=references,\n",
        "#     model_type=None,\n",
        "#     num_layers=None,\n",
        "#     verbose=True,\n",
        "#     idf=False,\n",
        "#     device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "#     batch_size=64,\n",
        "#     lang=None,\n",
        "#     return_hash=False,\n",
        "#     rescale_with_baseline=False,\n",
        "#     baseline_path=None,\n",
        "#     use_fast_tokenizer=True,\n",
        "#     custom_model=model,\n",
        "#     custom_tokenizer=tokenizer\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SQSC-Uy5EMyL"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1 = compute_bert_score(candidate_embeddings, reference_embeddings, candidate_mask, reference_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvz_1YnpC3NO",
        "outputId": "aca260b3-5eff-4b36-80dc-c60c820eb5ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5892\n",
            "Recall: 0.6949\n",
            "F1 Score: 0.6377\n"
          ]
        }
      ],
      "source": [
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXQrr_jkCzUE"
      },
      "source": [
        "##Prepare Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c8imMM8FMMQ4"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKXBc2ptAA-q"
      },
      "source": [
        "Please download the token of your kaggle account which is a file named kaggle.json and upload it to the colab's root. Then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df7cMhKrMPiN"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download mahbodissaiy/pubmed-publication-type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eK3JZmVS5mP"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file = \"pubmed-publication-type.zip\"\n",
        "with ZipFile(file, 'r') as zip:\n",
        "    zip.printdir()\n",
        "    print('extraction...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99918VB3UYoy",
        "outputId": "66477fec-e76b-443e-bd1b-50d102cb67df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   pubmed_id                                              title  \\\n",
            "0   37994819  Survival and mechanical complications of singl...   \n",
            "\n",
            "                                            abstract          type  label  \\\n",
            "0  PURPOSE: To evaluate the survival of and incid...  case-control      0   \n",
            "\n",
            "                                                text  \n",
            "0  Title:\\nSurvival and mechanical complications ...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('dataset_cleaned.csv')\n",
        "first_row = df.head(1)\n",
        "print(first_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBcTvuSmTZd4",
        "outputId": "a3d9b204-b7d0-4f08-84c6-d6dd58b9072e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New CSV file 'pmid_abstracts.csv' created successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "original_df = pd.read_csv('dataset_cleaned.csv')\n",
        "new_df = original_df[['pubmed_id', 'abstract']]\n",
        "\n",
        "new_df.to_csv('pmid_abstracts.csv', index=False)\n",
        "print(\"New CSV file 'pmid_abstracts.csv' created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC5UtXvyUpGW"
      },
      "source": [
        "QA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpBu-dFlxFYN"
      },
      "source": [
        "we chose PubMedQA dataset from this link for the QA part: https://huggingface.co/datasets/qiaojin/PubMedQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEW3JNtcUr6P"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"qiaojin/PubMedQA\", \"pqa_artificial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GMVZSMyCwikt"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('dataset_cleaned.csv')\n",
        "# from datasets import Dataset, DatasetDict\n",
        "\n",
        "# # Create a Dataset from the DataFrame\n",
        "# dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGFVWdk4aESm",
        "outputId": "2fecaebb-6b7d-4e3a-8ed8-ab096bd2f13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in train split:\n",
            "['pubid', 'question', 'context', 'long_answer', 'final_decision']\n"
          ]
        }
      ],
      "source": [
        "#see all the column titles of the dataset\n",
        "for split in ds.keys():\n",
        "    print(f\"Columns in {split} split:\")\n",
        "    print(ds[split].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhnm3wAT3qyr"
      },
      "source": [
        "we would like to remove the 'pubid' column for the dataset that we work on, cause it's not going to be of any use for our purpose. and keep the other columns. and also rename the 'long_answer' column to just 'answer' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoGdg1Qi372H",
        "outputId": "57db6f90-fa57-416a-c006-df30985edd42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in train split:\n",
            "['question', 'context', 'answer', 'final_decision']\n",
            "{'question': 'Are group 2 innate lymphoid cells ( ILC2s ) increased in chronic rhinosinusitis with nasal polyps or eosinophilia?', 'context': {'contexts': ['Chronic rhinosinusitis (CRS) is a heterogeneous disease with an uncertain pathogenesis. Group 2 innate lymphoid cells (ILC2s) represent a recently discovered cell population which has been implicated in driving Th2 inflammation in CRS; however, their relationship with clinical disease characteristics has yet to be investigated.', 'The aim of this study was to identify ILC2s in sinus mucosa in patients with CRS and controls and compare ILC2s across characteristics of disease.', 'A cross-sectional study of patients with CRS undergoing endoscopic sinus surgery was conducted. Sinus mucosal biopsies were obtained during surgery and control tissue from patients undergoing pituitary tumour resection through transphenoidal approach. ILC2s were identified as CD45(+) Lin(-) CD127(+) CD4(-) CD8(-) CRTH2(CD294)(+) CD161(+) cells in single cell suspensions through flow cytometry. ILC2 frequencies, measured as a percentage of CD45(+) cells, were compared across CRS phenotype, endotype, inflammatory CRS subtype and other disease characteristics including blood eosinophils, serum IgE, asthma status and nasal symptom score.', '35 patients (40% female, age 48 ± 17 years) including 13 with eosinophilic CRS (eCRS), 13 with non-eCRS and 9 controls were recruited. ILC2 frequencies were associated with the presence of nasal polyps (P = 0.002) as well as high tissue eosinophilia (P = 0.004) and eosinophil-dominant CRS (P = 0.001) (Mann-Whitney U). They were also associated with increased blood eosinophilia (P = 0.005). There were no significant associations found between ILC2s and serum total IgE and allergic disease. In the CRS with nasal polyps (CRSwNP) population, ILC2s were increased in patients with co-existing asthma (P = 0.03). ILC2s were also correlated with worsening nasal symptom score in CRS (P = 0.04).'], 'labels': ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS'], 'meshes': ['Adult', 'Aged', 'Antigens, Surface', 'Case-Control Studies', 'Chronic Disease', 'Eosinophilia', 'Female', 'Humans', 'Hypersensitivity', 'Immunity, Innate', 'Immunoglobulin E', 'Immunophenotyping', 'Leukocyte Count', 'Lymphocyte Subsets', 'Male', 'Middle Aged', 'Nasal Mucosa', 'Nasal Polyps', 'Neutrophil Infiltration', 'Patient Outcome Assessment', 'Rhinitis', 'Sinusitis', 'Young Adult']}, 'answer': 'As ILC2s are elevated in patients with CRSwNP, they may drive nasal polyp formation in CRS. ILC2s are also linked with high tissue and blood eosinophilia and have a potential role in the activation and survival of eosinophils during the Th2 immune response. The association of innate lymphoid cells in CRS provides insights into its pathogenesis.', 'final_decision': 'yes'}\n"
          ]
        }
      ],
      "source": [
        "ds = ds.remove_columns(\"pubid\")\n",
        "ds = ds.rename_column(\"long_answer\", \"answer\")\n",
        "\n",
        "for split in ds.keys():\n",
        "    print(f\"Columns in {split} split:\")\n",
        "    print(ds[split].column_names)\n",
        "    print(ds[split][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWZ9hnnU7G_h",
        "outputId": "4d00d20a-80c1-49e9-c20d-bbadec7c6d95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are group 2 innate lymphoid cells ( ILC2s ) increased in chronic rhinosinusitis with nasal polyps or eosinophilia?\n",
            "As ILC2s are elevated in patients with CRSwNP, they may drive nasal polyp formation in CRS. ILC2s are also linked with high tissue and blood eosinophilia and have a potential role in the activation and survival of eosinophils during the Th2 immune response. The association of innate lymphoid cells in CRS provides insights into its pathogenesis.\n",
            "dict_keys(['train'])\n"
          ]
        }
      ],
      "source": [
        "print(ds['train'][0]['question'])\n",
        "print(ds['train'][0]['answer'])\n",
        "print(ds.keys())\n",
        "\n",
        "ds = ds['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shp0vFU09Yix",
        "outputId": "f06b43b7-c1e9-4d70-edd4-daf858cd7ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'Are group 2 innate lymphoid cells ( ILC2s ) increased in chronic rhinosinusitis with nasal polyps or eosinophilia?', 'context': {'contexts': ['Chronic rhinosinusitis (CRS) is a heterogeneous disease with an uncertain pathogenesis. Group 2 innate lymphoid cells (ILC2s) represent a recently discovered cell population which has been implicated in driving Th2 inflammation in CRS; however, their relationship with clinical disease characteristics has yet to be investigated.', 'The aim of this study was to identify ILC2s in sinus mucosa in patients with CRS and controls and compare ILC2s across characteristics of disease.', 'A cross-sectional study of patients with CRS undergoing endoscopic sinus surgery was conducted. Sinus mucosal biopsies were obtained during surgery and control tissue from patients undergoing pituitary tumour resection through transphenoidal approach. ILC2s were identified as CD45(+) Lin(-) CD127(+) CD4(-) CD8(-) CRTH2(CD294)(+) CD161(+) cells in single cell suspensions through flow cytometry. ILC2 frequencies, measured as a percentage of CD45(+) cells, were compared across CRS phenotype, endotype, inflammatory CRS subtype and other disease characteristics including blood eosinophils, serum IgE, asthma status and nasal symptom score.', '35 patients (40% female, age 48 ± 17 years) including 13 with eosinophilic CRS (eCRS), 13 with non-eCRS and 9 controls were recruited. ILC2 frequencies were associated with the presence of nasal polyps (P = 0.002) as well as high tissue eosinophilia (P = 0.004) and eosinophil-dominant CRS (P = 0.001) (Mann-Whitney U). They were also associated with increased blood eosinophilia (P = 0.005). There were no significant associations found between ILC2s and serum total IgE and allergic disease. In the CRS with nasal polyps (CRSwNP) population, ILC2s were increased in patients with co-existing asthma (P = 0.03). ILC2s were also correlated with worsening nasal symptom score in CRS (P = 0.04).'], 'labels': ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS'], 'meshes': ['Adult', 'Aged', 'Antigens, Surface', 'Case-Control Studies', 'Chronic Disease', 'Eosinophilia', 'Female', 'Humans', 'Hypersensitivity', 'Immunity, Innate', 'Immunoglobulin E', 'Immunophenotyping', 'Leukocyte Count', 'Lymphocyte Subsets', 'Male', 'Middle Aged', 'Nasal Mucosa', 'Nasal Polyps', 'Neutrophil Infiltration', 'Patient Outcome Assessment', 'Rhinitis', 'Sinusitis', 'Young Adult']}, 'answer': 'As ILC2s are elevated in patients with CRSwNP, they may drive nasal polyp formation in CRS. ILC2s are also linked with high tissue and blood eosinophilia and have a potential role in the activation and survival of eosinophils during the Th2 immune response. The association of innate lymphoid cells in CRS provides insights into its pathogenesis.', 'final_decision': 'yes'}\n",
            "Are group 2 innate lymphoid cells ( ILC2s ) increased in chronic rhinosinusitis with nasal polyps or eosinophilia?\n"
          ]
        }
      ],
      "source": [
        "print(ds[0])\n",
        "print(ds[0]['question'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDu69LWn-NWe"
      },
      "source": [
        "so we got rid of the extra notation of ['train'] and dataset is accessible using ds variable right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHiOPlVH-1IJ"
      },
      "source": [
        "Later on based on the split you prefer, you can split it into 3 datasets like ds_train, ds_val and ds_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uff-oEg5_zoj"
      },
      "source": [
        "##Retrieval Model with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3IEVHlSwlkAq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxlLcBTQycCA"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p0NnAZxQf4W5"
      },
      "outputs": [],
      "source": [
        "all_abstracts = new_df[\"abstract\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "baPGUo0d_5Io"
      },
      "outputs": [],
      "source": [
        "contexts = all_abstracts\n",
        "questions = [item[\"question\"] for item in ds]\n",
        "answers = [item[\"answer\"] for item in ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jvz0nwFXlZ6y"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJvg-kEhzPUN",
        "outputId": "5166b959-890f-47a2-9d9d-86075bbb3d06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing contexts: 100%|██████████| 100093/100093 [02:04<00:00, 805.16it/s]\n"
          ]
        }
      ],
      "source": [
        "contexts_preprocessed = []\n",
        "for context in tqdm(contexts, desc=\"Processing contexts\"):\n",
        "    contexts_preprocessed.append(preprocess(context))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "O8vdYST0zRnO"
      },
      "outputs": [],
      "source": [
        "# questions_preprocessed = []\n",
        "# for question in tqdm(questions, desc=\"Processing questions\"):\n",
        "#     questions_preprocessed.append(preprocess(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPw8GG9el295",
        "outputId": "aa698ebd-3e8e-44e6-fb1b-e1f218f7ba4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Vectorizing...: 100%|██████████| 100093/100093 [00:10<00:00, 9175.17it/s]\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_contexts = vectorizer.fit_transform(tqdm(contexts_preprocessed, desc=\"Vectorizing...\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oxUeIQvkl4vr"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_texts(question, top_n=5):\n",
        "    question_preprocessed = preprocess(question)\n",
        "    question_vector = vectorizer.transform([question_preprocessed])\n",
        "    similarity_scores = cosine_similarity(question_vector, X_contexts).flatten()\n",
        "    relevant_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
        "    relevant_texts = [contexts[i] for i in relevant_indices]\n",
        "    return relevant_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTMBMJX0l6aU",
        "outputId": "d45baba6-434e-4070-ef6f-14094947adb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant Text 1:\n",
            "Atopic dermatitis (AD) is a common allergic inflammatory skin condition mainly caused by gene variants, immune disorders, and environmental risk factors. The T helper (Th) 2 immune response mediated by interleukin (IL)-4/13 is generally believed to be central in the pathogenesis of AD. It has been shown that innate lymphoid cells (ILCs) play a major effector cell role in the immune response in tissue homeostasis and inflammation and fascinating details about the interaction between innate and adaptive immunity. Changes in ILCs may contribute to the onset and progression of AD, and ILC2s especially have gained much attention. However, the role of ILCs in AD still needs to be further elucidated. This review summarizes the role of ILCs in skin homeostasis and highlights the signaling pathways in which ILCs may be involved in AD, thus providing valuable insights into the behavior of ILCs in skin homeostasis and inflammation, as well as new approaches to treating AD.\n",
            "\n",
            "Relevant Text 2:\n",
            "RORγt(+) group 3 innate lymphoid cells (ILC3s), the innate counterpart of Th17 cells, are enriched in the mucosal area and lymphoid tissues. ILC3s interact with a variety of cells through their effector molecules and play an important role in the host defense against a spectrum of infections. Recent studies suggest that the extensive crosstalk between ILC3s and adaptive immune cells, especially T cells, is essential for maintaining tissue homeostasis. Here we discuss recent advances in the crosstalk between ILC3s and adaptive immune responses in multiple tissues and diseases. Understanding how ILC3s engage with adaptive immune cells will enhance our comprehension of diseases and facilitate the identification of novel therapeutic targets.\n",
            "\n",
            "Relevant Text 3:\n",
            "OBJECTIVES: The French Society of ORL set up a work group to draw up a consensus document on the prescription of nebulization in rhinology. The document deals with the principles of and indications for rhinologic aerosol therapy. MATERIALS AND METHODS: The work group’s methodology followed the rules published by the French health authority (Haute Autorité de santé [HAS]) in January 2006: \"Methodological foundations for drawing up professional guidelines by formalized consensus\" (available on the HAS website athttp://www.has-sante.fr). The method used is the short version (without editorial group) of the RAND/UCLA Appropriateness Method; the short version was chosen because this particular consensus conference was dealing with a very precise topic with very few experts in the field. RESULTS: Sonic aerosol therapy with nasal plug is the preferred modality, delivering treatment into the middle meati. The group recommends that drugs with market authorization for use in bronchopulmonary pathology should be nebulized in two 10-minute sessions per day for at least seven days. Indications for rhinologic aerosol therapy are: purulent edematous rhinosinusitis, subacute rhinosinusitis (4–12 weeks’ evolution), exacerbations of chronic rhinosinusitis, and postoperative (>1 month) rhinosinus suppuration.Audiometric monitoring is required in iterative aminoside nebulization.Conclusion: Rhinologic aerosol therapy can be used in purulent edematous rhinosinusitis, subacute rhi-nosinusitis, exacerbations of chronic rhinosinusitis and postoperative rhinosinus suppuration. The rules for prescription contained in the present document optimize efficacy.\n",
            "\n",
            "Relevant Text 4:\n",
            "Innate lymphoid cells type 3 (ILC3s) are the first line sentinels at the mucous tissues, where they contribute to the homeostatic immune response in a major way. Also, they have been increasingly appreciated as important modulators of chronic inflammatory and autoimmune responses, both locally and systemically. The proper identification of ILC3 is of utmost importance for meaningful studies on their role in immunity. Flow cytometry is the method of choice for the detection and characterization of ILC3. However, the analysis of ILC3-related papers shows inconsistency in ILC3 phenotypic definition, as different inclusion and exclusion markers are used for their identification. Here, we present these discrepancies in the phenotypic characterization of human and mouse ILC3s. We discuss the pros and cons of using various markers for ILC3 identification. Furthermore, we consider the possibilities for the efficient isolation and propagation of ILC3 from different organs and tissues for in-vitro and in-vivo studies. This paper calls upon uniformity in ILC3 definition, isolation, and propagation for the increased possibility of confluent interpretation of ILC3's role in immunity.\n",
            "\n",
            "Relevant Text 5:\n",
            "Innate lymphoid cells type 3 (ILC3s) are the first line sentinels at the mucous tissues, where they contribute to the homeostatic immune response in a major way. Also, they have been increasingly appreciated as important modulators of chronic inflammatory and autoimmune responses, both locally and systemically. The proper identification of ILC3 is of utmost importance for meaningful studies on their role in immunity. Flow cytometry is the method of choice for the detection and characterization of ILC3. However, the analysis of ILC3-related papers shows inconsistency in ILC3 phenotypic definition, as different inclusion and exclusion markers are used for their identification. Here, we present these discrepancies in the phenotypic characterization of human and mouse ILC3s. We discuss the pros and cons of using various markers for ILC3 identification. Furthermore, we consider the possibilities for the efficient isolation and propagation of ILC3 from different organs and tissues for in-vitro and in-vivo studies. This paper calls upon uniformity in ILC3 definition, isolation, and propagation for the increased possibility of confluent interpretation of ILC3's role in immunity.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = \"What is the role of ILC2s in chronic rhinosinusitis?\"\n",
        "relevant_texts = retrieve_relevant_texts(question)\n",
        "for idx, text in enumerate(relevant_texts):\n",
        "    print(f\"Relevant Text {idx + 1}:\\n{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0XVkQ23mLqI"
      },
      "source": [
        "## Retrieval Model with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iQYpADYmZ7X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmKR2FfAmPwu"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih9VPESqmkCC"
      },
      "outputs": [],
      "source": [
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG6TpWXfmmGz"
      },
      "outputs": [],
      "source": [
        "context_embeddings = [get_bert_embedding(context) for context in tqdm(contexts, desc=\"Get embeddings of contexts...\", leave=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgRZAccwmn1H"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_texts(question, top_n=5):\n",
        "    question_embedding = get_bert_embedding(question)\n",
        "    similarity_scores = cosine_similarity([question_embedding], context_embeddings).flatten()\n",
        "    relevant_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
        "    relevant_texts = [contexts[i] for i in relevant_indices]\n",
        "    return relevant_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yaKbhXfmpPn"
      },
      "outputs": [],
      "source": [
        "question = \"What is the role of ILC2s in chronic rhinosinusitis?\"\n",
        "relevant_texts = retrieve_relevant_texts(question)\n",
        "for idx, text in enumerate(relevant_texts):\n",
        "    print(f\"Relevant Text {idx + 1}:\\n{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu_TnVrAryLM"
      },
      "source": [
        "## Retrieval Model with USE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rv21gPEz1OE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do0eOFu1r1RF"
      },
      "outputs": [],
      "source": [
        "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpdMlaBV5K2E"
      },
      "outputs": [],
      "source": [
        "def get_use_embedding(texts, batch_size=128):\n",
        "    embeddings = []\n",
        "    num_batches = len(texts) // batch_size + int(len(texts) % batch_size != 0)\n",
        "    with tqdm(total=num_batches, desc=\"Get embeddings of contexts...\", leave=True) as pbar:\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            batch_embeddings = use_model(batch_texts).numpy()\n",
        "            embeddings.append(batch_embeddings)\n",
        "            pbar.update(1)\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mjfxULKG5MMK"
      },
      "outputs": [],
      "source": [
        "context_embeddings = get_use_embedding(contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIPhWlnLz59V"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_texts(question, top_n=5):\n",
        "    question_embedding = get_use_embedding([question])[0]\n",
        "    similarity_scores = cosine_similarity([question_embedding], context_embeddings).flatten()\n",
        "    relevant_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
        "    relevant_texts = [contexts[i] for i in relevant_indices]\n",
        "    return relevant_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3qt0m_2z8Ck",
        "outputId": "67867024-fa38-49c8-e09f-4275d798e687"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Get embeddings of contexts...: 100%|██████████| 1/1 [00:00<00:00, 38.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant Text 1:\n",
            "What role do female sex hormones play in the antisperm immune response?\n",
            "\n",
            "Relevant Text 2:\n",
            "Chronic wounds cause significant morbidity and mortality and cost our health care system millions of dollars each year. A major impediment to wound healing is the formation of bacterial biofilms. Biofilms are communities of bacteria associated with chronic infections. This article reviews the literature on chronic wounds and biofilms. The role of biofilms in chronic wounds is not widely known. The purpose is to increase awareness of their role and to discuss research into novel therapeutic options. PubMed searches were performed to identify publications on chronic wounds and biofilms. Biofilms contribute to chronic wound nonhealing. There is an abundance of research into novel antibiofilm strategies for chronic wounds.\n",
            "\n",
            "Relevant Text 3:\n",
            "To review current knowledge of neurobiologic mechanisms that generate and maintain chronic pain and to explain how they might be applied in targeting treatment of chronic, inflammatory, and neuropathic pain syndromes. Published research, literature review articles, and abstracts as well as national statistics. Treatment for chronic pain associated with cancer and other syndromes remains suboptimal and falls significantly short of clinical needs. Data highlight the role that multiple neurobiologic mechanisms play in modulating and maintaining pain at various levels of the central and peripheral nervous systems. Novel agents have been developed that use a more targeted approach to treating chronic pain.\n",
            "\n",
            "Relevant Text 4:\n",
            "How does hypoxia-mediated down-regulation of dual specificity phosphatase-2 (DUSP2) promote endometriotic lesion development?\n",
            "\n",
            "Relevant Text 5:\n",
            "Do platelets play any role in the development of endometriosis?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = \"What is the role of ILC2s in chronic rhinosinusitis?\"\n",
        "relevant_texts = retrieve_relevant_texts(question)\n",
        "for idx, text in enumerate(relevant_texts):\n",
        "    print(f\"Relevant Text {idx + 1}:\\n{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ve5e4qVuA5M"
      },
      "source": [
        "# **Use T5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hnLwsJAquDUS"
      },
      "outputs": [],
      "source": [
        "number_of_questions = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PR4Xb58HvMtb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DtIHxreuJ5C",
        "outputId": "d7f62eb0-b0d1-43e8-987e-7563ea419196"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [25:22<00:00,  3.28it/s]\n"
          ]
        }
      ],
      "source": [
        "indices = random.sample(range(len(questions)), number_of_questions)\n",
        "\n",
        "question_and_contexts = list()\n",
        "answers_for_questions = list()\n",
        "\n",
        "for i in tqdm(indices):\n",
        "    question_and_contexts_sample = list()\n",
        "    question_and_contexts_sample.append(questions[i])\n",
        "    relevant_texts = retrieve_relevant_texts(questions[i], 3)\n",
        "    question_and_contexts_sample += relevant_texts\n",
        "    question_and_contexts.append(question_and_contexts_sample)\n",
        "\n",
        "    answers_for_questions.append(answers[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIC6BJn9wIYh"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-small\"\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr3FCGp_wRG4"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "t5_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9tRsSO5KwUcn"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question, passages):\n",
        "    context = \" \".join(passages)\n",
        "\n",
        "    input_text = f\"As an expert, you have the context information. Provide a clear and concise answer to the question based on the context. Step1: Read the context provided below. Step2: Answer the question based on the context. Context Information: {context}. Question: {question}.\"\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    output_ids = t5_model.generate(input_ids.to(device))\n",
        "    answer = t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOOSnoAuwXCZ",
        "outputId": "ce56476e-6bdb-4cdd-f9ad-f7363a8f1987"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "5000it [07:07, 11.70it/s]\n"
          ]
        }
      ],
      "source": [
        "predicted = list()\n",
        "labels = list()\n",
        "\n",
        "for i, question_and_context in tqdm(enumerate(question_and_contexts)):\n",
        "    question = question_and_context[0]\n",
        "    context = question_and_context[1:]\n",
        "    answer = generate_answer(question, context)\n",
        "    true_answer = answers_for_questions[i]\n",
        "\n",
        "    predicted.append(answer)\n",
        "    labels.append(true_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBVDPH7www2Q",
        "outputId": "1880fb5e-aacd-40a5-d1f8-248d44fc7c25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [26:23<00:00,  3.16it/s]\n"
          ]
        }
      ],
      "source": [
        "bleu1_list = list()\n",
        "bleu2_list = list()\n",
        "bleu3_list = list()\n",
        "bleu4_list = list()\n",
        "rouge1_list = list()\n",
        "rouge2_list = list()\n",
        "rougel_list = list()\n",
        "bert_score_p = list()\n",
        "bert_score_r = list()\n",
        "bert_score_f = list()\n",
        "\n",
        "for i in tqdm(range(len(predicted))):\n",
        "    current_predict = predicted[i]\n",
        "    current_answer = labels[i]\n",
        "\n",
        "    # bleu\n",
        "    bleu_scores = calculate_bleu(current_predict, [current_answer])\n",
        "    bleu1_list.append(bleu_scores['BLEU-1'])\n",
        "    bleu2_list.append(bleu_scores['BLEU-2'])\n",
        "    bleu3_list.append(bleu_scores['BLEU-3'])\n",
        "    bleu4_list.append(bleu_scores['BLEU-4'])\n",
        "\n",
        "    # rouge\n",
        "    rouge_scores = calculate_rouge(current_predict, current_answer)\n",
        "    rouge1_list.append(rouge_scores['ROUGE-1'])\n",
        "    rouge2_list.append(rouge_scores['ROUGE-2'])\n",
        "    rougel_list.append(rouge_scores['ROUGE-L'])\n",
        "\n",
        "    # bert score\n",
        "    candidate_embeddings, candidate_mask = get_embeddings([current_predict], tokenizer, model)\n",
        "    reference_embeddings, reference_mask = get_embeddings([current_answer], tokenizer, model)\n",
        "    precision, recall, f1 = compute_bert_score(candidate_embeddings, reference_embeddings, candidate_mask, reference_mask)\n",
        "    bert_score_p.append(precision)\n",
        "    bert_score_r.append(recall)\n",
        "    bert_score_f.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm4EWtq21yjW",
        "outputId": "f431678d-f7f1-45ff-abbe-1b18f1f3f9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU1: 0.004538666174139423\n",
            "BLEU2: 0.0013959532250833145\n",
            "BLEU3: 0.0008909783828991251\n",
            "BLEU4: 0.0006773222687819434\n",
            "ROUGE1: 0.0139998226878194\n",
            "ROUGE2: 0.00119076661741\n",
            "ROUGEL: 0.011943067132986\n",
            "Precision: 0.5754459087133408\n",
            "Recall: 0.243997132986784\n",
            "F1: 0.3316032350335642\n"
          ]
        }
      ],
      "source": [
        "print(\"BLEU1:\", sum(bleu1_list) / len(bleu1_list))\n",
        "print(\"BLEU2:\", sum(bleu2_list) / len(bleu2_list))\n",
        "print(\"BLEU3:\", sum(bleu3_list) / len(bleu3_list))\n",
        "print(\"BLEU4:\", sum(bleu4_list) / len(bleu4_list))\n",
        "print(\"ROUGE1:\", sum(rouge1_list), len(rouge1_list))\n",
        "print(\"ROUGE2:\", sum(rouge2_list), len(rouge2_list))\n",
        "print(\"ROUGEL:\", sum(rougel_list), len(rougel_list))\n",
        "print(\"Precision:\", sum(bert_score_p)/ len(bert_score_p))\n",
        "print(\"Recall:\", sum(bert_score_r)/ len(bert_score_r))\n",
        "print(\"F1:\", sum(bert_score_f)/ len(bert_score_f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmKXVOtj3v3L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "B8vKlQH-I_0H",
        "shVCNvkAMH44",
        "Uff-oEg5_zoj",
        "i0XVkQ23mLqI",
        "Hu_TnVrAryLM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
